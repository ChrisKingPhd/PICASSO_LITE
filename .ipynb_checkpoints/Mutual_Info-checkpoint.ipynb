{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e813fbd-e3ec-49e0-be9d-26d17aeab503",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import Statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8edde59f-c4de-49a0-adb4-5f32f609e513",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###############REQUIRED FOR PICASSO-LITE##################\n",
    "import numpy as np\n",
    "import scipy.optimize as so\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import random \n",
    "import copy\n",
    "##########################################################\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c575d5-adde-4b9b-9cfe-97e6febf7b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ddb06f0-02ff-4d85-899e-1dbd1df73097",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nchan_image(filepath):\n",
    "    imchans_list = []\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            im = Image.open(filepath)\n",
    "            num_chans = getattr(im, \"n_frames\", 1)\n",
    "            im.load()#PIL loads channel zero when .open is called initially\n",
    "            print(f\"This is a {num_chans} - channel file.\")\n",
    "            \n",
    "            data = np.array(im)\n",
    "\n",
    "            imchans_list.append(data)\n",
    "            for i in np.arange(1,num_chans):\n",
    "         \n",
    "                im.seek(i)#move to channel i \n",
    "                im.load()#get the pixel-level data\n",
    "                data = np.array(im)#convert to numpy array   \n",
    "  \n",
    "                imchans_list.append(data)\n",
    "\n",
    "            return num_chans, imchans_list\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to load the image from {filepath}. Error {str(e)}\")\n",
    "            return [],[]\n",
    "    \n",
    "    else:\n",
    "        raise FileNotFoundError(f\"The file {filepath} does not exist\")\n",
    "        return [],[]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab1eaf0-1454-4e21-bf5a-efc998a48a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a 3 - channel file.\n"
     ]
    }
   ],
   "source": [
    "#load the 3 channel laser scanning confocal tiff file provided by the PICASSO method authors\n",
    "filename = '3color_data.tif'\n",
    "filepath = os.path.join(\"D:/images/\", filename)\n",
    "num_chans, test = load_nchan_image(filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1118c5-1dfe-49b8-b95e-dee83cd072e8",
   "metadata": {},
   "source": [
    "# PICASSO-LITE Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18332fa4-76ec-43e8-9c96-41ed62a7a3d9",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class MI_unmixer: \n",
    "    \n",
    "    def __init__(self, n_color=0, maxIter = 8, learn_rate = 0.65, qQ = 200,qN = 100):\n",
    "        \n",
    "        self.n_color = n_color\n",
    "        self.maxIter = maxIter#maximum number of iterations\n",
    "        self.learn_rate = learn_rate#learning rate for unmixing\n",
    "        self.qQ = qQ#number of bins for 16bit range quantization\n",
    "        self.qN = qN#number of bins for 2d histograms\n",
    "        self.ops_list = []#unmixing operations list. each entry in the list is one unmixing step. \n",
    "        self.encoder = KBinsDiscretizer(n_bins=qQ, encode=\"ordinal\", strategy=\"uniform\", random_state=42)#encoder for unmixing\n",
    "    \n",
    "    def mi_normalize(self,hyperspec_img):\n",
    "        #[0:max] normalizeation of each channel, if using pseudochannels, these should be created prior to normalization.\n",
    "        #background model should be subracted before normalization\n",
    "        \n",
    "        \n",
    "        nch,nrow,ncol = hyperspec_img.shape\n",
    "        \n",
    "            \n",
    "        norm_data = np.zeros((hyperspec_img.shape))\n",
    "        \n",
    "        for chn in np.arange(nch):\n",
    "            \n",
    "            single_img = hyperspec_img[chn,:,:] \n",
    "            \n",
    "                \n",
    "            chmax = np.nanpercentile(single_img.flatten(),100)\n",
    "               \n",
    "            norm_img= (single_img)/(chmax)\n",
    "            norm_img[norm_img < 0 ] = 0\n",
    "            \n",
    "            \n",
    "            norm_data[chn,:,:] = norm_img\n",
    "        return norm_data \n",
    "    \n",
    "    def objective(self,x,XY):#function of optimization for MI-based unmixing\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        X_j = XY[1,:]\n",
    "        X_i = XY[0,:]\n",
    "    \n",
    "        nr = np.shape(X_j)[0]\n",
    "        rand_img = np.random.rand((nr))\n",
    "    \n",
    "        total_pix = len(X_j)\n",
    "\n",
    "        scaled_diff = X_i - x*X_j\n",
    "        num_neg = np.sum([scaled_diff < 0])#the cost function to minimize includes the number of negative pixels\n",
    "    \n",
    "        neg_img = np.copy(scaled_diff)\n",
    "    \n",
    "    \n",
    "        frac_neg = num_neg/total_pix\n",
    "    \n",
    "        neg_img[neg_img > 0] = 0.01*rand_img[neg_img > 0]#0\n",
    "        neg_img = np.abs(neg_img)\n",
    "    \n",
    "        diff_mi = self.mutual_info(X_j, scaled_diff)\n",
    "        neg_mi = self.mutual_info(X_j,neg_img)\n",
    "    \n",
    "    \n",
    "        return diff_mi + neg_mi + frac_neg #+ x**2\n",
    "    \n",
    "    def mutual_info(self, im1, im2):\n",
    "        qN = self.qN\n",
    "        hist_2d, x_edges, y_edges = np.histogram2d(im1, im2, bins=qN)\n",
    "        #print(np.max(im1))\n",
    "        #print(np.max(im2))\n",
    "        # Convert bins counts to probability values\n",
    "        pxy = hist_2d /float(np.sum(hist_2d))\n",
    "        px = np.sum(pxy, axis=1) # marginal for x over y\n",
    "        py = np.sum(pxy, axis=0) # marginal for y over x\n",
    "        px_py = px[:, None] * py[None, :] # Broadcast to multiply marginals\n",
    "    \n",
    "        # Now we can do the calculation using the pxy, px_py 2D arrays\n",
    "        nzs = pxy > 0 # Only non-zero pxy values contribute to the sum\n",
    "        #print(nzs.shape)\n",
    "        mutual_info = np.sum(pxy[nzs] * np.log(pxy[nzs] / px_py[nzs]))\n",
    "    \n",
    "        return mutual_info\n",
    "    \n",
    "    def quantize(self, img):\n",
    "        qQuant = self.qQ\n",
    "        #img is image data: nrow x mcol image. single slice. \n",
    "        #qQuant is the number of bins\n",
    "              \n",
    "        compressed = np.zeros(img.shape)\n",
    "        compressed = self.encoder.fit_transform(img.reshape(-1, 1)).reshape(img.shape)/(qQuant-1)\n",
    "        \n",
    "        return compressed\n",
    "    \n",
    "    def mi_datashaper(self,img_stack):\n",
    "        #function to shape hyperspectral image cubes (l-channels x m rows x n columns) into l-channels x m*n columns\n",
    "        reshaped = np.reshape(img_stack,(img_stack.shape[0],-1))\n",
    "        \n",
    "        return reshaped\n",
    "    \n",
    "    def mi_fit(self, im_stack):\n",
    "        np.random.seed(42)\n",
    "        #im_stack is the m-channel x n pixel mixed image set ->reshape c*x*y image cube to 2D\n",
    "        n_color, npix = np.shape(im_stack) #number of channels and pixels in the hyperspectral image\n",
    "        \n",
    "        self.n_color = n_color\n",
    "        learn_rate = self.learn_rate\n",
    "        \n",
    "        X = im_stack\n",
    "        \n",
    "        \n",
    "        bound = [(0, 1)] #set positive contraints for alpha values\n",
    "\n",
    "        num_iter = 0#number iterations\n",
    "        \n",
    "        alpha_mat = 0.1*np.random.rand(n_color,n_color) +0.1 #matrix to hold the unmixing coefficients\n",
    "        P = np.array(np.identity(n_color)) #matrix like alpha_mat but with negative signs in front of non-diagonal entries\n",
    "\n",
    "        encoder = self.encoder#encoder for unmixing\n",
    "\n",
    "        unmix_ops_list = np.zeros((self.maxIter,n_color,n_color)) #keep the unmixing matrix for each iteration\n",
    "        \n",
    "        #alpha_mat diagonals must == 1:\n",
    "        \n",
    "        alpha_mat[P==1] = 1\n",
    "        \n",
    "        beta_mat = np.zeros((n_color,n_color))\n",
    "    \n",
    "        while num_iter < self.maxIter:\n",
    "            \n",
    "            num_iter += 1\n",
    "        \n",
    "            \n",
    "                \n",
    "            rand_img = np.random.rand((npix))#used in optimization function\n",
    "            print(num_iter)\n",
    "            \n",
    "            #normalize the data\n",
    "            for color in np.arange(n_color):\n",
    "                       \n",
    "                temp = X[color,:]\n",
    "                Xmax = np.nanpercentile(temp.flatten(),100)\n",
    "                \n",
    "                beta_mat[color,:] = Xmax\n",
    "                \n",
    "                XX = (X[color,:])/(Xmax)\n",
    "                XX[XX<0] = 0\n",
    "\n",
    "                X[color,:] = XX  \n",
    "            \n",
    "            Xq = self.quantize(X)\n",
    "           \n",
    "            for ch in range(P.shape[0]):\n",
    "                #print(ch)\n",
    "                for dy in range(P.shape[1]):\n",
    "                \n",
    "                    if ch != dy: #diagonals are == 1\n",
    "\n",
    "                        Xj = Xq[dy,:]\n",
    "                        Xi = Xq[ch,:]\n",
    "                    \n",
    "                        X_Y = np.zeros((2,Xj.shape[0]))\n",
    "                        X_Y[0,:] = Xi\n",
    "                        X_Y[1,:] = Xj\n",
    "           \n",
    "                        alpha = alpha_mat[ch,dy]\n",
    "                        \n",
    "                        results = so.minimize(self.objective, x0=alpha, args=X_Y, bounds=bound,method='Powell',options = {'xtol':0.001,'ftol':0.001,'maxiter':5000}) #x0 must have ndims = 1\n",
    "                        \n",
    "                        alpha_mat[ch,dy] = results.x#\n",
    "                        P[ch,dy] = (-1)*learn_rate*alpha_mat[ch,dy]\n",
    "\n",
    "            #hold the unmixing iteration array\n",
    "            unmix_ops_list[num_iter-1,:,:] = P\n",
    "            \n",
    "            #perform the  unmixing\n",
    "            \n",
    "            BP = np.multiply(beta_mat,P)\n",
    "            \n",
    "            X = np.matmul(BP,X) \n",
    "            X[X<0] = 0\n",
    "        \n",
    "            \n",
    "                \n",
    "                      \n",
    "        self.ops_list = unmix_ops_list\n",
    "   \n",
    "        return self\n",
    "    \n",
    "    def mi_transform(self,im_stack):\n",
    "        #im_stack is the m-channel x n pixel mixed image set ->reshape c,x,y image cube to 2D\n",
    "        if len(self.ops_list) > 0:\n",
    "            X = im_stack\n",
    "            beta_mat = np.zeros((self.n_color,self.n_color))\n",
    "            for operation in range(len(self.ops_list)):\n",
    "                \n",
    "                P = self.ops_list[operation]\n",
    "                n_color = P.shape[0]\n",
    "                #normalize the data\n",
    "                for color in np.arange(n_color):\n",
    "                       \n",
    "                    temp = X[color,:]\n",
    "                    Xmax = np.nanpercentile(temp.flatten(),100)\n",
    "                \n",
    "                    beta_mat[color,:] = Xmax\n",
    "                \n",
    "                    XX = (X[color,:])/(Xmax)\n",
    "                    XX[XX<0] = 0\n",
    "\n",
    "                    X[color,:] = XX  \n",
    "            \n",
    "                               \n",
    "                BP = np.multiply(beta_mat,P)\n",
    "                X = np.matmul(BP,X) \n",
    "                X[X<0] = 0\n",
    "                   \n",
    "             \n",
    "            return X                       \n",
    "        else:\n",
    "            print('error: model not trained on data')\n",
    "            return []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6e988-4323-48e4-a1b2-1d1317f858df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f992bacc-75b9-4a28-9a58-f2f1a6fa0245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7fa05-9fee-4458-a98f-f3142a3db3a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eab8d1-22b9-4e50-ad6e-2904facc9d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
