{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e813fbd-e3ec-49e0-be9d-26d17aeab503",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Import Statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edde59f-c4de-49a0-adb4-5f32f609e513",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "###############REQUIRED FOR PICASSO-LITE##################\n",
    "import numpy as np\n",
    "import scipy.optimize as so\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import random \n",
    "import copy\n",
    "##########################################################\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "os.chdir('C:/Users/Chris')\n",
    "#import MIunmixer2 as mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b30474b-22a5-4ec3-b283-59f0bcd4c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c68ed5-657b-48af-85ad-54e8814e7a67",
   "metadata": {},
   "source": [
    "## Some useful function definitions\n",
    "### Load n-channel tiff stacks. \n",
    "#### If the files are very large (stitched images) adjust the PIL maximum image size allowed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb06f0-02ff-4d85-899e-1dbd1df73097",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def load_nchan_image(filepath):\n",
    "    imchans_list = []\n",
    "    if os.path.exists(filepath):\n",
    "        try:\n",
    "            im = Image.open(filepath)\n",
    "            num_chans = getattr(im, \"n_frames\", 1)\n",
    "            im.load()#PIL loads channel zero when .open is called initially\n",
    "            print(f\"This is a {num_chans} - channel file.\")\n",
    "            \n",
    "            data = np.array(im)\n",
    "\n",
    "            imchans_list.append(data)\n",
    "            for i in np.arange(1,num_chans):\n",
    "         \n",
    "                im.seek(i)#move to channel i \n",
    "                im.load()#get the pixel-level data\n",
    "                data = np.array(im)#convert to numpy array   \n",
    "  \n",
    "                imchans_list.append(data)\n",
    "\n",
    "            return num_chans, imchans_list\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to load the image from {filepath}. Error {str(e)}\")\n",
    "            return [],[]\n",
    "    \n",
    "    else:\n",
    "        raise FileNotFoundError(f\"The file {filepath} does not exist\")\n",
    "        return [],[]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5c266a-31cc-4caa-b3c3-da413b80c853",
   "metadata": {},
   "source": [
    "### A function to create montages from tiff stacks imported as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ef3783-d833-4f08-ab70-6d407608e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_montage(im_stack, titles = [], outpath = [], numcols = 5, numrows = 1,lower_pct = 1, upper_pct = 99, show_montage = False):\n",
    "    #this function makes a montage of the input image stack, with the titles provided\n",
    "\n",
    "    n_color = im_stack.shape[0]\n",
    "    col = numcols\n",
    "    if col > n_color:\n",
    "        col = n_color\n",
    "    \n",
    "    \n",
    "    num_rows = np.floor(np.around(n_color/col))\n",
    "\n",
    "    remainder = np.remainder(n_color,num_rows)\n",
    "\n",
    "    if n_color > num_rows*col:\n",
    "        num_rows += 1\n",
    "    \n",
    "\n",
    "    ff,aa = plt.subplots(np.int_(num_rows),np.int_(col),figsize=(3*col,3*num_rows))\n",
    "    aa = aa.ravel()\n",
    "\n",
    "    \n",
    "    for idx,ax in enumerate(aa):\n",
    "        if idx < n_color:\n",
    "        \n",
    "            single_slice = np.copy(im_stack[idx,:])\n",
    "       \n",
    "        \n",
    "        \n",
    "            im_max = np.nanpercentile(single_slice,upper_pct)\n",
    "            im_min = np.nanpercentile(single_slice,lower_pct)\n",
    "            \n",
    "        \n",
    "        \n",
    "            ax.imshow(single_slice,vmin = im_min, vmax = im_max,cmap = 'gray',interpolation=None)\n",
    "            if len(titles) > 0:\n",
    "                ax.set_title(titles[idx],fontsize = 20)\n",
    "            else:\n",
    "                ax.set_title(str(idx),fontsize = 20)\n",
    "            \n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.001)\n",
    "    \n",
    "    if outpath:\n",
    "        plt.savefig(outpath,bbox_inches='tight', dpi=300)\n",
    "        \n",
    "    if not show_montage:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b07d7de-9402-4685-9afb-63e4ae166fd4",
   "metadata": {},
   "source": [
    "### The following cell defines functions for making RGB composite images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb032c84-66f7-49e8-b6d9-2e4046bfd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "#color dict is the list of colors to choose from. Add more colors if you want. \n",
    "color_dict = {'blue':[0,0,1], 'green':[0, 1, 0],'red':[1, 0, 0],'magenta':[1,0,1],'cyan': [0, 1, 1],'yellow':[1, 1, 0],'gray':[1,1,1]}\n",
    "    \n",
    "\n",
    "def colorize(im,color):#im needs to be a single channel image. normalized and clipped\n",
    "    #im is an mxn numpy array representing a grayscale image. \n",
    "    #color is the text string for the color this image should be in the composite. \n",
    "    \n",
    "    color_im = np.zeros((3,im.shape[0],im.shape[1]))\n",
    "    \n",
    "    for i in [0,1,2]:\n",
    "        color_array = color_dict[color]\n",
    "        \n",
    "        color_im[i,:,:] = im*float(color_array[i])\n",
    "    \n",
    "    return color_im\n",
    "\n",
    "\n",
    "def normalize_and_clip(im,pct_lo,pct_hi,ignore_sat_pixels = True):\n",
    "    #function to normalize images with quantile percentages lo and hi. then clip values \n",
    "    #below zero and above one\n",
    "    #im is an mxn numpy array representing a grayscale image. \n",
    "    #pct_low is a float in the range [0,100]\n",
    "    #pct_hi is a float in the range [0,100]\n",
    "    #ignore_sat_pixels  = True causes the function to ignore saturated pixels when normalizing\n",
    "\n",
    "    if  not ignore_sat_pixels:\n",
    "        temp = np.copy(im)\n",
    "        temp = temp[temp < 65000]\n",
    "        \n",
    "        lo = np.nanpercentile(temp,pct_lo)\n",
    "        hi = np.nanpercentile(temp,pct_hi)\n",
    "        #print('ignoring sat')\n",
    "    \n",
    "    elif ignore_sat_pixels:\n",
    "        lo = np.nanpercentile(im,pct_lo)\n",
    "        hi = np.nanpercentile(im,pct_hi)\n",
    "    \n",
    "    newim = (im - lo)/(hi-lo)\n",
    "    \n",
    "  \n",
    "    newim[newim < 0] = 0\n",
    "    newim[newim > 1] = 1\n",
    "    \n",
    "    return newim\n",
    "    \n",
    "    \n",
    "def save_composite(im_stack,outpath,channels,colors):\n",
    "    #a function to save composite images\n",
    "    #im is an mxn numpy array representing a grayscale image.    \n",
    "    #outpath is a string with save location\n",
    "    #channels is a list of ints representing specific channels to use in the composite\n",
    "    #colors is a list of strings for the color dictionary, length needs to be equal to length of channels\n",
    "    subset = im_stack[channels,:,:]\n",
    "  \n",
    "    \n",
    "    subset_shape = subset.shape\n",
    "    \n",
    "    \n",
    "    comp_image  = np.zeros((3,subset_shape[1],subset_shape[2]))\n",
    "    for chan in range(subset_shape[0]):\n",
    "        \n",
    "        temp = normalize_and_clip(subset[chan],5,99.5,ignore_sat_pixels = False)\n",
    "        temp = colorize(temp,colors[chan])\n",
    "        comp_image += temp\n",
    "    \n",
    "    rgb_composite = normalize_and_clip(comp_image,5,99.5,ignore_sat_pixels = True)\n",
    "    rgb_composite = np.transpose(rgb_composite, (1, 2, 0))#reshape the array for RGB type data\n",
    "          \n",
    "    plt.imsave(outpath, rgb_composite)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477f39ca-9653-4a6a-9eed-303336777580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee0d8830-882f-4cdf-9dc0-bf8c1e684f50",
   "metadata": {},
   "source": [
    "### Load the PICASSO paper-provided 3 channel fluorescence microscopy image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1eaf0-1454-4e21-bf5a-efc998a48a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load the 3 channel laser scanning confocal tiff file provided by the PICASSO method authors\n",
    "filename = '3color_data.tif'\n",
    "filepath = os.path.join(\"D:/images/\", filename)\n",
    "num_chans, test = load_nchan_image(filepath)\n",
    "test = np.asarray(test)\n",
    "make_montage(test, titles = ['Channel 1','Channel 2','Channel 3'],\n",
    "             outpath = \"D:/images/raw_montage.png\", numcols = 3, numrows = 1,lower_pct = 5, upper_pct = 99.5, show_montage = True)\n",
    "orig_shape = test.shape\n",
    "\n",
    "colors = ['blue','green','red']#,'gray','blue','magenta','cyan']\n",
    "save_composite(test,\"D:/images/raw_comoposite.png\",np.arange(3),colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46dd60-f28a-4e97-9750-51cb4774aeea",
   "metadata": {},
   "source": [
    "### Investigate the behavior of the mutual information between images as a function of alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6986b76-72bd-465f-afe0-7b6ea75b4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mutual_info(im1, im2,qN):\n",
    "    \n",
    "    hist_2d, x_edges, y_edges = np.histogram2d(im1, im2, bins=qN)\n",
    "   \n",
    "    # Convert bins counts to probability values\n",
    "    pxy = hist_2d /float(np.sum(hist_2d))\n",
    "    px = np.sum(pxy, axis=1) # marginal for x over y\n",
    "    py = np.sum(pxy, axis=0) # marginal for y over x\n",
    "    px_py = px[:, None] * py[None, :] # Broadcast to multiply marginals\n",
    "\n",
    "    # Now we can do the calculation using the pxy, px_py 2D arrays\n",
    "    nzs = pxy > 0 # Only non-zero pxy values contribute to the sum\n",
    "    #print(nzs.shape)\n",
    "    mutual_info = np.sum(pxy[nzs] * np.log(pxy[nzs] / px_py[nzs]))\n",
    "\n",
    "    return mutual_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d45747f-7ced-4da3-b392-b97fd467a45d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make plots\n",
    "alphas = np.linspace(0, 1, num=21, endpoint=True)\n",
    "\n",
    "\n",
    "pair1 = (test[0,:],test[1,:])\n",
    "pair2 = (test[0,:],test[2,:])\n",
    "pair3 = (test[1,:],test[2,:])\n",
    "pair4 = (test[1,:],test[0,:])\n",
    "pair5 = (test[2,:],test[0,:])\n",
    "pair6 = (test[2,:],test[1,:])\n",
    "\n",
    "pairlist = [pair1,pair2,pair3,pair4,pair5,pair6]\n",
    "difflist = []\n",
    "negimlist = []\n",
    "MIlist = []\n",
    "neglist = []\n",
    "diffMIlist = []\n",
    "for alpha in alphas: \n",
    "    print(alpha)\n",
    "    #compare the values of the mutual information for Imagej1 with Image_i - alpha*Image_j as a function of alpha\n",
    "    \n",
    "    sub_difflist = []#list of images\n",
    "    sub_neg = []#list of negative images\n",
    "    sub_MIlist = []#list of MI values\n",
    "    sub_neglist = []#list of negative pixel fractions\n",
    "    sub_diffMI = [] #list of MI values between Xj and the negative image of Xi - alpha*Xj\n",
    "    for count, pair in enumerate(pairlist):\n",
    "        #print(alpha, count)\n",
    "        #form the difference image\n",
    "        diff = pair[0] - alpha*pair[1]\n",
    "        imshape = diff.shape\n",
    "        \n",
    "        #form the \"negative image\" caused by over subtraction\n",
    "        neg_img = np.zeros(imshape)\n",
    "        neg_img[diff<0] = np.abs(diff[diff<0])#the \"negative image\" is the absolute value of the negative pixel values. \n",
    "        rand_img = np.random.rand(imshape[0],imshape[1])\n",
    "        neg_img[diff > 0] = 0.01*rand_img[diff > 0] #add random noise to the 'zero' area of the negative image to prevent a false increase in MI\n",
    "        neg_img = np.abs(neg_img)\n",
    "        sub_neg.append(neg_img)\n",
    "        #calculate the negative fraction of pixels\n",
    "        frac_neg = np.sum(diff < 0)/(imshape[0]*imshape[1])\n",
    "        sub_neglist.append(frac_neg)\n",
    "\n",
    "\n",
    "\n",
    "        #set negative pixels to zero in the corrected difference image. \n",
    "        diff[diff<0] = 0\n",
    "        sub_difflist.append(diff)\n",
    "\n",
    "\n",
    "        #calculate the mutual information between image j and the difference image\n",
    "        mutinf = mutual_info(pair[1].flatten(),diff.flatten(), qN = 100)\n",
    "        sub_MIlist.append(mutinf)\n",
    "        #print(mutinf)        \n",
    "        #calculate the mutual information between image j and the negative difference image\n",
    "        diff_MI = mutual_info(pair[1].flatten(), neg_img.flatten(), qN = 100)\n",
    "        sub_diffMI.append(diff_MI)\n",
    "\n",
    "        # fig, axes = plt.subplots(4, 1, figsize = (6,12))\n",
    "        # ax1, ax2, ax3, ax4 = axes.flatten()\n",
    "        # im_max = np.nanpercentile(pair[0],99.5)\n",
    "        # im_min = np.nanpercentile(pair[0],5)\n",
    "        # ax1.imshow(pair[0],vmin = im_min, vmax = im_max,cmap = 'gray',interpolation=None)\n",
    "        # im_max = np.nanpercentile(pair[1],99.5)\n",
    "        # im_min = np.nanpercentile(pair[1],5)\n",
    "        # ax2.imshow(pair[1], vmin = im_min, vmax = im_max,cmap = 'gray',interpolation=None)\n",
    "        # im_max = np.nanpercentile(diff,99.5)\n",
    "        # im_min = np.nanpercentile(diff,5)\n",
    "        # ax3.imshow(diff, vmin = im_min, vmax = im_max,cmap = 'gray',interpolation=None)\n",
    "        # im_max = np.nanpercentile(neg_img,99.5)\n",
    "        # im_min = np.nanpercentile(neg_img,5)\n",
    "        # ax4.imshow(neg_img, vmin = im_min, vmax = im_max,cmap = 'gray',interpolation=None)\n",
    "        # ax1.set_title(r'Image $X_i$')\n",
    "        # ax2.set_title(r'Image $X_j$')\n",
    "        # ax3.set_title(r'$(X_i - \\alpha X_j)$')\n",
    "        # ax4.set_title(r'Negative Image from $(X_i - \\alpha X_j)$')\n",
    "        # # remove the x and y ticks\n",
    "        # for ax in axes:\n",
    "        #     ax.set_xticks([])\n",
    "        #     ax.set_yticks([])\n",
    "        # fig.tight_layout()\n",
    "        # #plt.show()\n",
    "        # plt.savefig(str(alpha) + 'pair_' + str(count) + '.png')\n",
    "    \n",
    "    negimlist.append(sub_difflist)\n",
    "    difflist.append(sub_difflist)\n",
    "    MIlist.append(sub_MIlist)\n",
    "    neglist.append(sub_neglist)\n",
    "    diffMIlist.append(sub_diffMI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d12afd4-25ce-49ce-8d50-5b210ff89100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ad1b68-6358-4042-9f38-8b8ec2dbbfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.asarray(neglist).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f5e21-0501-4828-af26-6378180d8e4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c53d8d-0833-4267-bfe2-c307b6317640",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=4, ncols=1, sharex=True, sharey=False, figsize=(9,12))\n",
    "ax1, ax2, ax3, ax4 = axes.flatten()\n",
    "\n",
    "SMALL_SIZE = 20\n",
    "MEDIUM_SIZE = 25\n",
    "BIGGER_SIZE = 40\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=SMALL_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    "ax1.plot(MIlist)\n",
    "\n",
    "ax2.plot(diffMIlist)\n",
    "ax3.plot(neglist)\n",
    "ax4.plot(np.array(diffMIlist) + np.array(MIlist) + np.array(neglist))\n",
    "\n",
    "loss = np.array(diffMIlist) + np.array(MIlist) + np.array(neglist)\n",
    "min_losses = np.min(loss, axis=0)\n",
    "print(min_losses)\n",
    "min_args = np.argmin(loss, axis=0)\n",
    "print(min_args)\n",
    "\n",
    "ax4.plot(min_args,min_losses,'kx')\n",
    "\n",
    "# Create the legend\n",
    "from matplotlib.lines import Line2D\n",
    "cmap = plt.cm.tab20\n",
    "custom_lines = [Line2D([0], [0], color=\"#1f77b4\", lw=4),\n",
    "                Line2D([0], [0], color=\"#ff7f0e\", lw=4),\n",
    "                Line2D([0], [0], color=\"#2ca02c\", lw=4),\n",
    "                Line2D([0], [0], color=\"#d62728\", lw=4),\n",
    "                Line2D([0], [0], color= \"#9467bd\", lw=4),\n",
    "                Line2D([0], [0], color=\"#8c564b\", lw=4)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax1.set_title(r'$I(X_j , X_i - \\alpha X_j)$ vs. $\\alpha$')\n",
    "ax1.set_ylabel(r'$I(X_j , X_i - \\alpha X_j)$')\n",
    "ax1.set_ylim([0, 1.1])\n",
    "ax1.set_xticks([0, 5, 10, 15, 20], [str(alphas[0]), str(alphas[5]), str(alphas[10]), str(alphas[15]), str(alphas[20])], color='red', fontsize=12)\n",
    "\n",
    "ax2.set_title(r'$I(X_j, (X_i - \\alpha X_j)_{Neg.Img.})$ vs. $\\alpha$')\n",
    "ax2.set_ylabel(r'$I(X_j , X_i - \\alpha X_j)_{Neg.Img.})$')\n",
    "ax2.set_ylim([0, 1.1])\n",
    "\n",
    "ax3.set_title(r'Negative Pixel Fraction in $(X_i - \\alpha X_j)$ vs. $\\alpha$')\n",
    "ax3.set_ylabel(r'Fraction')\n",
    "ax3.set_ylim([0, 1.1])\n",
    "\n",
    "ax4.set_title(r'$L(I,I_{neg. Im.},frac_{neg.})$ vs. $\\alpha$')\n",
    "ax4.set_ylabel(r'Loss')\n",
    "ax4.set_ylim([0, 1.1])\n",
    "fig.supxlabel(r'Alpha ($\\alpha$)')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.legend(custom_lines, ['${X_0, X_1}$', '${X_0, X_2}$', '${X_1, X_2}$', '${X_1, X_0}$', \n",
    "                          '${X_2, X_0}$', '${X_2, X_1}$'],loc='upper right', bbox_to_anchor=(1.22, 1.0),title=r\"$X_i, X_j$ Pairs\")\n",
    "plt.savefig('plotsoflossprops'+'.png')\n",
    "plt.show()\n",
    "#the easiest way to plot these these would be to use pandas dataframes. old code dies hard. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef5b14-139b-4525-a702-d802514d5ed5",
   "metadata": {},
   "source": [
    "### Unmix the 3 channel dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34effb1-8f20-4fd3-9e1e-d09cb233af98",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = np.reshape(test,(orig_shape[0],-1)).astype(float) #num_chans rows by m times n total pixels (columns)\n",
    "my_unmixer = MI_unmixer(n_color=3, maxIter = 2, learn_rate = 1, qQ = 300,qN = 100)\n",
    "\n",
    "my_unmixer.mi_fit(testing) #fit the subsampled data\n",
    "unmixed = my_unmixer.mi_transform(np.copy(testing))\n",
    "unmixed = np.reshape(unmixed, orig_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca02b3d-2179-4f69-aa93-029f42fb7703",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped = unmixed[:,200:700,400:900]\n",
    "\n",
    "make_montage(unmixed, titles = ['Channel 1','Channel 2','Channel 3'],\n",
    "             outpath = \"D:/images/unmixed_montage.png\", numcols = 3, numrows = 1,lower_pct = 5, upper_pct = 99.5, show_montage = True)\n",
    "\n",
    "make_montage(cropped, titles = ['Channel 1','Channel 2','Channel 3'],\n",
    "             outpath = \"D:/images/cropped_unmixed_montage.png\", numcols = 3, numrows = 1,lower_pct = 5, upper_pct = 99.5, show_montage = True)\n",
    "\n",
    "\n",
    "colors = ['blue','green','red']\n",
    "save_composite(unmixed,\"D:/images/unmixed_composite.png\",np.arange(3),colors)\n",
    "save_composite(cropped,\"D:/images/cropped_unmixed_composite.png\",np.arange(3),colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e025db-5b7b-48e7-a2fc-43c41749346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you want to look at the unmixing matrix values, use the .ops_list property. the alpha values do not converge to zero. once the major structures have been removed from other channels, the algorithm works on small random noise differences. \n",
    "#i would recommend using something like the gradient of the SSIM to determine stopping criteria if that was desired. the goal is to run in two iterations, thus two iterations is my stopping criterion. \n",
    "print((my_unmixer.ops_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85ad35-92a3-45ce-ad15-702d364a894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7285a5-ae09-4d31-b471-bc4f01bc307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_test = test[:,200:700,400:900]\n",
    "make_montage(cropped_test, titles = ['Channel 1','Channel 2','Channel 3'],\n",
    "             outpath = \"D:/images/cropped_raw_montage.png\", numcols = 3, numrows = 1,lower_pct = 5, upper_pct = 99.5, show_montage = True)\n",
    "save_composite(cropped_test,\"D:/images/cropped_raw_composite.png\",np.arange(3),colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5cca3a-aade-46f2-8486-3eec41d8a2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deee22fd-1963-4686-a9de-ed44ff5f4688",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c1118c5-1dfe-49b8-b95e-dee83cd072e8",
   "metadata": {},
   "source": [
    "# PICASSO-LITE Class Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d6e988-4323-48e4-a1b2-1d1317f858df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "class MI_unmixer: \n",
    "    \n",
    "    def __init__(self, n_color=0, maxIter = 2, learn_rate = 1, qQ = 300,qN = 100):\n",
    "        \n",
    "        self.n_color = n_color\n",
    "        self.maxIter = maxIter#maximum number of iterations\n",
    "        self.learn_rate = learn_rate#learning rate for unmixing\n",
    "        self.qQ = qQ#number of bins for 16bit range quantization\n",
    "        self.qN = qN#number of bins for 2d histograms\n",
    "        self.ops_list = []#unmixing operations list. each entry in the list is one unmixing step. \n",
    "        self.encoder = KBinsDiscretizer(n_bins=qQ, encode=\"ordinal\", strategy=\"uniform\", random_state=42)#encoder for unmixing\n",
    "    \n",
    "    def objective(self,x,XY):#function of optimization for MI-based unmixing\n",
    "        np.random.seed(42)\n",
    "        \n",
    "        X_j = XY[1,:]\n",
    "        X_i = XY[0,:]\n",
    "    \n",
    "        nr = np.shape(X_j)[0]\n",
    "        rand_img = np.random.rand((nr))\n",
    "    \n",
    "        total_pix = len(X_j)\n",
    "\n",
    "        scaled_diff = X_i - x*X_j\n",
    "        num_neg = np.sum([scaled_diff < 0])#the cost function to minimize includes the number of negative pixels\n",
    "    \n",
    "        neg_img = np.copy(scaled_diff)\n",
    "    \n",
    "    \n",
    "        frac_neg = num_neg/total_pix\n",
    "    \n",
    "        neg_img[neg_img > 0] = 0.01*rand_img[neg_img > 0]#0\n",
    "        neg_img = np.abs(neg_img)\n",
    "    \n",
    "        diff_mi = self.mutual_info(X_j, scaled_diff)\n",
    "        neg_mi = self.mutual_info(X_j,neg_img)\n",
    "    \n",
    "    \n",
    "        return diff_mi + neg_mi + frac_neg #+ x**2\n",
    "    \n",
    "    def mutual_info(self, im1, im2):\n",
    "        qN = self.qN\n",
    "        hist_2d, x_edges, y_edges = np.histogram2d(im1, im2, bins=qN)\n",
    "\n",
    "        # Convert bins counts to probability values\n",
    "        pxy = hist_2d /float(np.sum(hist_2d))\n",
    "        px = np.sum(pxy, axis=1) # marginal for x over y\n",
    "        py = np.sum(pxy, axis=0) # marginal for y over x\n",
    "        px_py = px[:, None] * py[None, :] # Broadcast to multiply marginals\n",
    "    \n",
    "        #the calculation using the pxy, px_py 2D arrays\n",
    "        nzs = pxy > 0 # Only non-zero pxy values contribute to the sum\n",
    "\n",
    "        mutual_info = np.sum(pxy[nzs] * np.log(pxy[nzs] / px_py[nzs]))\n",
    "    \n",
    "        return mutual_info\n",
    "    \n",
    "    def quantize(self, img):\n",
    "        qQuant = self.qQ\n",
    "        #img is image data: nrow x mcol image. single slice. \n",
    "        #qQuant is the number of bins\n",
    "\n",
    "        #print('im min: ', np.min(img))\n",
    "        #print('im max: ', np.max(img))\n",
    "        compressed = np.zeros(img.shape)\n",
    "        compressed = self.encoder.fit_transform(img.reshape((-1, 1))).reshape(img.shape)/(qQuant-1)#quantize the entire hyperspectral image at once, not each channel separately. \n",
    "        #this preserves within-channel spatial signal relationships and inter-channel signal relationships\n",
    "\n",
    "        return compressed\n",
    "    \n",
    "    def mi_datashaper(self,img_stack):\n",
    "        #function to shape hyperspectral image cubes (l-channels x m rows x n columns) into l-channels x m*n columns\n",
    "        reshaped = np.reshape(img_stack,(img_stack.shape[0],-1))\n",
    "        \n",
    "        return reshaped\n",
    "\n",
    "    def subsample_img(self, im_stack,subsamp_pct = 1.0, mask=None):\n",
    "    #a function to subsample hyperspectral images\n",
    "    #im_stack is the m-channel x n pixel mixed image set ->reshape c*x*y image cube to 2D\n",
    "    #mask is a 2d image reshaped into 1D array->.flatten()\n",
    "    #this function randomly subsamples the mask or the whole field\n",
    "    #print(im_stack.shape)#number of channels and pixels in the hyperspectral image\n",
    "    #print(subsamp_pct*npix)\n",
    "        if subsamp_pct < 1.0:\n",
    "            if mask is not None:\n",
    "                mask[mask > 0] = 1\n",
    "                goodpix = 1-mask\n",
    "                \n",
    "                good_indices = goodpix.nonzero()\n",
    "                \n",
    "                \n",
    "                im_stack = np.squeeze(im_stack[:,good_indices])\n",
    "                \n",
    "          \n",
    "                n_color, npix = np.shape(im_stack)\n",
    "                \n",
    "                numpixels = np.round(subsamp_pct*npix)\n",
    "           \n",
    "            \n",
    "                subsamp_img = np.zeros((n_color,numpixels.astype(int)))\n",
    "            \n",
    "                ran_indices = np.random.choice(npix, (1,numpixels.astype(int)), replace=False)\n",
    "                \n",
    "                for chans, _ in enumerate(im_stack):\n",
    "                    subsamp_img[chans,:] = im_stack[chans,ran_indices]\n",
    "                return subsamp_img\n",
    "            \n",
    "            else:#not using a mask\n",
    "                \n",
    "                n_color, npix = np.shape(im_stack)\n",
    "                numpixels = np.round(subsamp_pct*npix)\n",
    "                        \n",
    "                subsamp_img = np.zeros((n_color,numpixels.astype(int)))\n",
    "            \n",
    "                ran_indices = np.random.choice(npix, (1,numpixels.astype(int)), replace=False)\n",
    "                \n",
    "                for chans,rows in enumerate(im_stack):\n",
    "                    subsamp_img[chans,:] = im_stack[chans,ran_indices]\n",
    "                return subsamp_img\n",
    "            \n",
    "        else:\n",
    "            return im_stack\n",
    "    \n",
    "    def mi_fit(self, im_stack):\n",
    "        np.random.seed(42)\n",
    "        #im_stack is the m-channel x n pixel mixed image set ->reshape c*x*y image cube to 2D\n",
    "        n_color, npix = np.shape(im_stack) #number of channels and pixels in the hyperspectral image\n",
    "\n",
    "        self.n_color = n_color\n",
    "        learn_rate = self.learn_rate\n",
    "        \n",
    "        X = im_stack\n",
    "       \n",
    "        bound = [(0, 1)] #set positive contraints for alpha values\n",
    "\n",
    "        num_iter = 0#number iterations\n",
    "        \n",
    "        alpha_mat = 0.1*np.random.rand(n_color,n_color) +0.1 #matrix to hold the unmixing coefficients\n",
    "        P = np.array(np.identity(n_color)) #matrix like alpha_mat but with negative signs in front of non-diagonal entries\n",
    "\n",
    "        encoder = self.encoder#encoder for unmixing\n",
    "\n",
    "        unmix_ops_list = np.zeros((self.maxIter,n_color,n_color)) #keep the unmixing matrix for each iteration\n",
    "        \n",
    "        #alpha_mat diagonals must == 1:\n",
    "        \n",
    "        alpha_mat[P==1] = 1\n",
    "        \n",
    "        beta_mat = np.zeros((n_color,n_color))\n",
    "    \n",
    "        while num_iter < self.maxIter:\n",
    "            \n",
    "            num_iter += 1\n",
    "        \n",
    "            print('Iteration #:', num_iter)\n",
    "            \n",
    "            #normalize the data\n",
    "            for color in np.arange(n_color):\n",
    "                       \n",
    "                temp = X[color,:]\n",
    "\n",
    "                Xmax = np.nanpercentile(temp.flatten(),100)\n",
    "\n",
    "                beta_mat[color,:] = Xmax\n",
    "                \n",
    "                XX = (X[color,:])/(Xmax)\n",
    "                XX[XX<0] = 0\n",
    "\n",
    "                X[color,:] = XX  \n",
    "            \n",
    "            Xq = self.quantize(X)\n",
    "           \n",
    "            for ch in range(P.shape[0]):\n",
    "\n",
    "                for dy in range(P.shape[1]):\n",
    "                \n",
    "                    if ch != dy: #diagonals are == 1\n",
    "\n",
    "                        Xj = Xq[dy,:]\n",
    "                        Xi = Xq[ch,:]\n",
    "                    \n",
    "                        X_Y = np.zeros((2,Xj.shape[0]))\n",
    "                        X_Y[0,:] = Xi\n",
    "                        X_Y[1,:] = Xj\n",
    "           \n",
    "                        alpha = alpha_mat[ch,dy]\n",
    "                        \n",
    "                        results = so.minimize(self.objective, x0=alpha, args=X_Y, bounds=bound,method='Powell',options = {'xtol':0.001,'ftol':0.001,'maxiter':5000}) #x0 must have ndims = 1\n",
    "                        \n",
    "                        alpha_mat[ch,dy] = results.x#there's no real need to actually hold the 'alpha_mat'. This is just a holdover from me trying to recreate the PICASSO method\n",
    "                        P[ch,dy] = (-1)*learn_rate*alpha_mat[ch,dy]\n",
    "\n",
    "            #hold the unmixing iteration array\n",
    "            unmix_ops_list[num_iter-1,:,:] = P\n",
    "            \n",
    "            #perform the  unmixing\n",
    "            \n",
    "            BP = np.multiply(beta_mat,P)\n",
    "            \n",
    "            X = np.matmul(BP,X) \n",
    "            X[X<0] = 0#negative pixels don't exist in real life.\n",
    "                      \n",
    "        self.ops_list = unmix_ops_list\n",
    "   \n",
    "        return self\n",
    "    \n",
    "    def mi_transform(self,im_stack):\n",
    "        #im_stack is the m-channel x n pixel mixed image set ->reshape c,x,y image cube to 2D\n",
    "        if len(self.ops_list) > 0:\n",
    "            X = im_stack\n",
    "            beta_mat = np.zeros((self.n_color,self.n_color))\n",
    "            for operation in range(len(self.ops_list)):\n",
    "                \n",
    "                P = self.ops_list[operation]\n",
    "                n_color = P.shape[0]\n",
    "                #normalize the data\n",
    "                for color in np.arange(n_color):\n",
    "                       \n",
    "                    temp = X[color,:]\n",
    "                    Xmax = np.nanpercentile(temp.flatten(),100)\n",
    "                \n",
    "                    beta_mat[color,:] = Xmax\n",
    "                \n",
    "                    XX = (X[color,:])/(Xmax)\n",
    "                    XX[XX<0] = 0\n",
    "\n",
    "                    X[color,:] = XX  \n",
    "            \n",
    "                               \n",
    "                BP = np.multiply(beta_mat,P)\n",
    "                X = np.matmul(BP,X) \n",
    "                X[X<0] = 0\n",
    "                   \n",
    "             \n",
    "            return X                       \n",
    "        else:\n",
    "            print('error: model not trained on data')\n",
    "            return []\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6699769e-b360-4fd6-9e1e-8b33bb27bd14",
   "metadata": {},
   "source": [
    "### a fast positively-constrained linear least squares fitting algorithm for comparison with PICASSO-Lite if the individual spectra are available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab7fa05-9fee-4458-a98f-f3142a3db3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_linearunmix(design_mat,data):\n",
    "    #import numpy as np\n",
    "    #this function implements a fast and loose (brute force) positive constraints unmixing algorithm that I came up with. it is really fast.  \n",
    "    #design_mat is a matrix where the columns are the minmax normalized spectra of the individual components. m channels by n dyes\n",
    "    #data is a m channels by n pixels array\n",
    "    a = design_mat\n",
    "    app = np.ones((a.shape[0],1))\n",
    "    a = np.append(a,app,axis=1)                 \n",
    "    \n",
    "    orig_coeffs,_,_,_ = np.linalg.lstsq(a, data,rcond=None)\n",
    "    coeffs = np.array(np.copy(orig_coeffs))\n",
    "\n",
    "    #we want to go through all combinations of dyes and refit the pixels with negative fit coefficients\n",
    "\n",
    "    num_dyes = a.shape[1] #number of dyes used\n",
    "\n",
    "    column_listing = np.arange(num_dyes)\n",
    "\n",
    "    already_analyzed = np.empty(coeffs.shape)\n",
    "\n",
    "    #Column 0 is the background (Autofluorescence)column. \n",
    "\n",
    "    for i in range(1,num_dyes)[::-1]:\n",
    "\n",
    "        column_selections = np.asarray(list(iterator.combinations(range(1,num_dyes),i)))\n",
    "\n",
    "        for j in range(column_selections.shape[0]):\n",
    "\n",
    "            working_on = column_selections[j,:]\n",
    "            not_workingon = np.setdiff1d(column_listing,working_on)\n",
    "\n",
    "            pixels = np.empty(coeffs.shape)\n",
    "            pixels = coeffs < 0\n",
    "            totalbad = np.sum(pixels,0)\n",
    "\n",
    "            bad_pixels = np.empty(coeffs[working_on,:].shape)\n",
    "            bad_pixels = coeffs[working_on,:] < 0\n",
    "\n",
    "            sumofbad = np.sum(bad_pixels,0)\n",
    "\n",
    "            pixels_selection = (sumofbad == i) & (totalbad > 0)\n",
    "            #print('reanalyzing pixels: ', np.sum(pixels_selection*1),' pixels')\n",
    "\n",
    "            pixels_toanalyze = np.squeeze(data[:,pixels_selection])\n",
    "            #print('shape of pixels_toanalyze: ',pixels_toanalyze.shape)\n",
    "\n",
    "            if i == num_dyes -1:\n",
    "                #make the new support matrix\n",
    "                #all the dye coefficients are negative, refit with only BG model\n",
    "                aprime = np.zeros((a.shape[0],1))\n",
    "                aprime[:,0] = a[:,0]\n",
    "            else:\n",
    "                if np.sum(pixels_selection)>0:\n",
    "                    aprime = np.zeros((a.shape[0],num_dyes - i))\n",
    "\n",
    "                    aprime = a[:,not_workingon]\n",
    "\n",
    "                #else:\n",
    "                    #print('i did nothing')\n",
    "            if np.sum(pixels_selection) > 0:        \n",
    "                temp_coeffs,_,_,_ = np.linalg.lstsq(aprime, pixels_toanalyze,rcond=None)\n",
    "\n",
    "\n",
    "                coeffs[working_on[:,None], pixels_selection] = 0  ## [:,None] allows proper indexing of the 2D array coeffs\n",
    "\n",
    "                if temp_coeffs.ndim > 1:    \n",
    "                    temp_coeffs[already_analyzed[not_workingon[:,None],pixels_selection] == 1] = 0\n",
    "\n",
    "                    if i <= num_dyes/2:\n",
    "                        temp_coeffs[temp_coeffs < 0] = 0\n",
    "                        coeffs[not_workingon[:,None],pixels_selection] = temp_coeffs\n",
    "                else:\n",
    "\n",
    "                    if temp_coeffs[0] > 0:\n",
    "                        coeffs[not_workingon[:,None],pixels_selection] = temp_coeffs[0]\n",
    "                    else:\n",
    "                        coeffs[not_workingon[:,None],pixels_selection] = 0\n",
    "\n",
    "                #update the already_analyzed variable to list the pixel coefficients we already worked on for being negative    \n",
    "                already_analyzed[working_on[:,None],pixels_selection] = 1\n",
    "    #final cleanup of negatives    \n",
    "    coeffs[coeffs < 0] = 0\n",
    "    \n",
    "    return coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eab8d1-22b9-4e50-ad6e-2904facc9d0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
